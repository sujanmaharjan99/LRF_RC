{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d893e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station 01_Rulo ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 02_St_Joseph ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 03_Kansas_City ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 04_Waverly ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 05_Boonville ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 06_Hermann ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 07_St_Charles ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 08_Grafton ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 09_ST_Louis ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 10_Chester ===\n",
      "  Found subfolders: ['All', 'mem1', 'mem4', 'mem3', 'mem2']\n",
      "\n",
      "=== Station 11_Thebes ===\n",
      "  Found subfolders: ['All']\n",
      "[csv] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/KGE_by_station_and_lead.csv\n",
      "[csv] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/Merged_obs_vs_fcst_timeseries.csv\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/01_Rulo_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/02_St_Joseph_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/03_Kansas_City_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/04_Waverly_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/05_Boonville_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/06_Hermann_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/07_St_Charles_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/08_Grafton_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/09_ST_Louis_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/10_Chester_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/11_Thebes_KGE_vs_lead.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/01_Rulo_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/02_St_Joseph_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/03_Kansas_City_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/04_Waverly_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/05_Boonville_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/06_Hermann_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/07_St_Charles_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/08_Grafton_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/09_ST_Louis_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/10_Chester_timeseries_check.png\n",
      "[plot] wrote /media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare/11_Thebes_timeseries_check.png\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "########################################\n",
    "# Config\n",
    "########################################\n",
    "\n",
    "stations = [\n",
    "    \"01_Rulo\",\n",
    "    \"02_St_Joseph\",\n",
    "    \"03_Kansas_City\",\n",
    "    \"04_Waverly\",\n",
    "    \"05_Boonville\",\n",
    "    \"06_Hermann\",\n",
    "    \"07_St_Charles\",\n",
    "    \"08_Grafton\",\n",
    "    \"09_ST_Louis\",\n",
    "    \"10_Chester\",\n",
    "    \"11_Thebes\"\n",
    "]\n",
    "\n",
    "usgs_ids = [\n",
    "    \"01_Rulo_06813500.csv\",\n",
    "    \"02_St_Joseph_06818000.csv\",\n",
    "    \"03_Kansas_City_06893000.csv\",\n",
    "    \"04_Waverly_06895500.csv\",\n",
    "    \"05_Boonville_06909000.csv\",\n",
    "    \"06_Hermann_06934500.csv\",\n",
    "    \"07_St_Charles_06935965.csv\",\n",
    "    \"08_Grafton_05587450.csv\",\n",
    "    \"09_ST_Louis_07010000.csv\",\n",
    "    \"10_Chester_07020500.csv\",\n",
    "    \"11_Thebes_07022000.csv\"\n",
    "]\n",
    "\n",
    "BASE_NWM_DIR = Path(\"/media/12TB/Sujan/NWM/Csv\")\n",
    "BASE_USGS_DIR = Path(\"/media/12TB/Sujan/NWM/USGS_data\")\n",
    "OUT_DIR = Path(\"/media/12TB/Sujan/NWM/Codes/LRF_RC/NWM_Q_to_GH/Discharge_forecast_compare\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "########################################\n",
    "# Helpers\n",
    "########################################\n",
    "\n",
    "def kge(sim, obs):\n",
    "    \"\"\"\n",
    "    Kling-Gupta Efficiency\n",
    "    \"\"\"\n",
    "    sim = np.asarray(sim, dtype=float)\n",
    "    obs = np.asarray(obs, dtype=float)\n",
    "\n",
    "    mask = np.isfinite(sim) & np.isfinite(obs)\n",
    "    if mask.sum() < 3:\n",
    "        return np.nan\n",
    "\n",
    "    sim = sim[mask]\n",
    "    obs = obs[mask]\n",
    "\n",
    "    r = np.corrcoef(sim, obs)[0, 1]\n",
    "    alpha = np.std(sim) / np.std(obs) if np.std(obs) != 0 else np.nan\n",
    "    beta = np.mean(sim) / np.mean(obs) if np.mean(obs) != 0 else np.nan\n",
    "\n",
    "    return 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "\n",
    "\n",
    "def subset_label(raw_name):\n",
    "    \"\"\"\n",
    "    Map folder name to nice label for legend/CSV.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"All\": \"Ensemble mean\",\n",
    "        \"mem1\": \"Ensemble member 1\",\n",
    "        \"mem2\": \"Ensemble member 2\",\n",
    "        \"mem3\": \"Ensemble member 3\",\n",
    "        \"mem4\": \"Ensemble member 4\",\n",
    "    }\n",
    "    return mapping.get(raw_name, raw_name)\n",
    "\n",
    "\n",
    "def get_lead_hours_from_filename(fname):\n",
    "    \"\"\"\n",
    "    Extract lead hours from filename like timeseries_006.csv OR timeseries_090.csv.\n",
    "    We'll pull the numeric part after underscore.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"timeseries_(\\d+)\\.csv$\", fname)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot parse lead hours from filename {fname}\")\n",
    "\n",
    "\n",
    "def plot_kge_vs_lead(df_station_kge, station_name, out_dir):\n",
    "    \"\"\"\n",
    "    Scatter plot: KGE vs lead days per subset for one station.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "    for subset, subdf in df_station_kge.groupby(\"Subset\"):\n",
    "        ax.scatter(\n",
    "            subdf[\"LeadDays\"],\n",
    "            subdf[\"KGE\"],\n",
    "            s=25,\n",
    "            alpha=0.8,\n",
    "            label=subset\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Lead time (days)\")\n",
    "    ax.set_ylabel(\"KGE\")\n",
    "    ax.set_title(f\"{station_name}: KGE vs lead time (NWM discharge vs USGS)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(title=\"Subset\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    outfile = out_dir / f\"{station_name}_KGE_vs_lead.png\"\n",
    "    fig.savefig(outfile, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"[plot] wrote {outfile}\")\n",
    "\n",
    "\n",
    "def plot_sample_timeseries(df_merged_station, station_name, out_dir, lead_hours_list=[24,72,120]):\n",
    "    \"\"\"\n",
    "    QC plot: USGS vs Ensemble mean forecast for a few leads.\n",
    "    df_merged_station columns: valid_time, Q_USGS_cms, Q_fcst_cms, lead_hours, Subset\n",
    "    We'll only plot Subset == 'Ensemble mean'.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "    # Observations\n",
    "    obs_only = (\n",
    "        df_merged_station[[\"valid_time\",\"Q_USGS_cms\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values(\"valid_time\")\n",
    "    )\n",
    "    ax.plot(\n",
    "        obs_only[\"valid_time\"],\n",
    "        obs_only[\"Q_USGS_cms\"],\n",
    "        linewidth=2,\n",
    "        label=\"Observed (USGS)\"\n",
    "    )\n",
    "\n",
    "    # Ensemble mean\n",
    "    emean = df_merged_station[df_merged_station[\"Subset\"] == \"Ensemble mean\"].copy()\n",
    "    for lh in lead_hours_list:\n",
    "        sub = emean[emean[\"lead_hours\"] == lh].sort_values(\"valid_time\")\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        ax.plot(\n",
    "            sub[\"valid_time\"],\n",
    "            sub[\"Q_fcst_cms\"],\n",
    "            linewidth=1,\n",
    "            alpha=0.8,\n",
    "            label=f\"Ens mean +{lh/24:.0f}d\"\n",
    "        )\n",
    "\n",
    "    ax.set_title(f\"{station_name}: Discharge timeseries (obs vs NWM Ens mean)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Discharge (cumecs)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    outfile = out_dir / f\"{station_name}_timeseries_check.png\"\n",
    "    fig.savefig(outfile, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"[plot] wrote {outfile}\")\n",
    "\n",
    "\n",
    "########################################\n",
    "# Main processing\n",
    "########################################\n",
    "\n",
    "all_kge_records = []\n",
    "all_merged_allstations = []\n",
    "\n",
    "for i, stn in enumerate(stations):\n",
    "    print(f\"\\n=== Station {stn} ===\")\n",
    "\n",
    "    # 1. Load USGS data\n",
    "    usgs_file = BASE_USGS_DIR / usgs_ids[i]\n",
    "    usgs_df = pd.read_csv(usgs_file, parse_dates=[\"timestamp\"])\n",
    "    # Normalize column names\n",
    "    usgs_df = usgs_df.rename(columns={\n",
    "        \"timestamp\": \"valid_time\",\n",
    "        \"discharge_cumecs\": \"Q_USGS_cms\"\n",
    "    })\n",
    "    usgs_df = usgs_df[[\"valid_time\", \"Q_USGS_cms\"]].dropna()\n",
    "\n",
    "    # 2. Discover forecast member folders\n",
    "    station_dir = BASE_NWM_DIR / stn\n",
    "    if not station_dir.exists():\n",
    "        print(f\"[warn] Directory not found for {stn}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    subfolders = [p for p in station_dir.iterdir() if p.is_dir()]\n",
    "    if not subfolders:\n",
    "        print(f\"[warn] No subfolders in {station_dir}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(\"  Found subfolders:\", [sf.name for sf in subfolders])\n",
    "\n",
    "    merged_this_station = []\n",
    "\n",
    "    # 3. Loop forecast subsets (All, mem1, mem2, mem3, mem4)\n",
    "    for subfolder in subfolders:\n",
    "        raw_subset = subfolder.name\n",
    "        pretty_subset = subset_label(raw_subset)\n",
    "\n",
    "        # gather all timeseries_*.csv in this subfolder\n",
    "        files = sorted(subfolder.glob(\"timeseries_*.csv\"))\n",
    "        if not files:\n",
    "            print(f\"    [warn] No timeseries_*.csv in {subfolder}\")\n",
    "            continue\n",
    "\n",
    "        rows_list = []\n",
    "\n",
    "        for fpath in files:\n",
    "            # extract lead hours from filename\n",
    "            lead_h = get_lead_hours_from_filename(fpath.name)\n",
    "\n",
    "            df_fcst = pd.read_csv(fpath, parse_dates=[\"time\"])\n",
    "            # standardize forecast columns\n",
    "            df_fcst = df_fcst.rename(columns={\n",
    "                \"time\": \"valid_time\",\n",
    "                \"streamflow\": \"Q_fcst_cms\"\n",
    "            })\n",
    "            df_fcst[\"lead_hours\"] = lead_h\n",
    "            df_fcst[\"LeadDays\"] = df_fcst[\"lead_hours\"] / 24.0\n",
    "            df_fcst[\"Subset\"] = pretty_subset\n",
    "            df_fcst[\"Station\"] = stn\n",
    "\n",
    "            rows_list.append(df_fcst[[\"valid_time\",\"Q_fcst_cms\",\"lead_hours\",\"LeadDays\",\"Subset\",\"Station\"]])\n",
    "\n",
    "        if not rows_list:\n",
    "            continue\n",
    "\n",
    "        fcst_all = pd.concat(rows_list, ignore_index=True)\n",
    "\n",
    "        # 4. Merge with USGS obs on valid_time\n",
    "        merged = pd.merge(\n",
    "            fcst_all,\n",
    "            usgs_df,\n",
    "            on=\"valid_time\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        if merged.empty:\n",
    "            print(f\"    [warn] No overlap in time for {stn} {pretty_subset}\")\n",
    "            continue\n",
    "\n",
    "        merged_this_station.append(merged)\n",
    "\n",
    "    # done looping over members for this station\n",
    "    if not merged_this_station:\n",
    "        print(f\"[warn] nothing merged for station {stn}\")\n",
    "        continue\n",
    "\n",
    "    merged_station_full = pd.concat(merged_this_station, ignore_index=True)\n",
    "    all_merged_allstations.append(merged_station_full)\n",
    "\n",
    "    # 5. Compute KGE for each subset / lead_hours\n",
    "    for (subset_name, lead_h), dgrp in merged_station_full.groupby([\"Subset\",\"lead_hours\"]):\n",
    "        kge_val = kge(dgrp[\"Q_fcst_cms\"].values, dgrp[\"Q_USGS_cms\"].values)\n",
    "\n",
    "        all_kge_records.append({\n",
    "            \"Station\": stn,\n",
    "            \"Subset\": subset_name,\n",
    "            \"LeadHours\": lead_h,\n",
    "            \"LeadDays\": lead_h / 24.0,\n",
    "            \"KGE\": kge_val\n",
    "        })\n",
    "\n",
    "# Combine results across stations\n",
    "kge_table = pd.DataFrame(all_kge_records)\n",
    "merged_all_df = pd.concat(all_merged_allstations, ignore_index=True) if all_merged_allstations else pd.DataFrame()\n",
    "\n",
    "########################################\n",
    "# Save CSV outputs\n",
    "########################################\n",
    "\n",
    "kge_csv_path = OUT_DIR / \"KGE_by_station_and_lead.csv\"\n",
    "kge_table.to_csv(kge_csv_path, index=False)\n",
    "print(f\"[csv] wrote {kge_csv_path}\")\n",
    "\n",
    "merged_csv_path = OUT_DIR / \"Merged_obs_vs_fcst_timeseries.csv\"\n",
    "merged_all_df.to_csv(merged_csv_path, index=False)\n",
    "print(f\"[csv] wrote {merged_csv_path}\")\n",
    "\n",
    "########################################\n",
    "# Plots\n",
    "########################################\n",
    "\n",
    "# 1. KGE vs lead time for each station\n",
    "for stn, df_stn in kge_table.groupby(\"Station\"):\n",
    "    plot_kge_vs_lead(df_stn, stn, OUT_DIR)\n",
    "\n",
    "# 2. QC time series, plotting only ensemble mean\n",
    "for stn, df_stn in merged_all_df.groupby(\"Station\"):\n",
    "    plot_sample_timeseries(df_stn, stn, OUT_DIR, lead_hours_list=[24,72,120])\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LRF_RC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
